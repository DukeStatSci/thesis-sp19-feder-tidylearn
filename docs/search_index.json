[
["index.html", "Evaluating Student Creativity, Depth and Multivariate Visualizations of Data Analysis projects based on R Syntax and Packages Abstract Acknowledgements Dedication", " Evaluating Student Creativity, Depth and Multivariate Visualizations of Data Analysis projects based on R Syntax and Packages Benjamin Feder May 2019 Abstract Programming has become an essential component of introductory statistics, as students use R to explore general concepts. Currently, there are two methods of teaching R for beginning statisticians, but not much literature on how they affect student comprehension and analysis. We analyzed 205 final projects written using the two syntaxes for an introductory statistics course at Duke University from the 2013-2016 academic years, creating a variety of indicator variables to measure their creativity, depth and the complexity of multivariate visualizations. Student projects using the tidyverse syntax were found to score significantly higher on all three metrics, suggesting instructors should employ the tidyverse when teaching beginning statistics. Based on these results from the retrospective study, we created resources designed for future use in statistical instruction. Keywords: Introductory statistics, Education, Tidyverse, Creativity, Depth, Multivariate visualizations, Retrospective study Acknowledgements I thank my advisor, Dr. Mine Çetinkaya-Rundel for her immense dedication and support in supervising this project. I could not have done this without her, let alone obtain a legitimate dataset to perform a comparative analysis. I also thank Dr. Victoria Ellison for her essential advice, and the Department of Statistical Science for providing me with the tools to complete this project. Most of all, I thank my family and friends for their love and belief in me for the past 21 years. Dedication I dedicate my thesis to my past students for whom I have been a teaching assistant for their enthusiasm that gave me the motivation to complete this thesis. "],
["1-introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction At Duke University, STA 101 is the primary introductory statistics course, where students are assumed to have entered the class without any statistical knowledge. The majority of students enrolled in the course do not plan on enrolling in future statistics curricula, focusing the course on applications of statistics, as students learn how to relate STA 101’s concepts to their future works. At the beginning of the course, the students are divided into groups where they complete assignments throughout the course together. The class is split into seven units, and every section has at least one lab, taught in R, to bolster the learning segment. For introductory statistics courses, the Guidelines for Assessment and Instruction in Statistics Education (GAISE) sets the standard, as it provides a set of general recommendations, as well as specific goals to be accomplished by the course’s completion. With its updated version released in 2016, the GAISE, which is endorsed by the American Statistical Association, recommends that students use programming, if accessible, to explore real-world examples of concepts covered in the classroom. To conclude the semester, students display their grasp of the course through a group project conducted in R. A sufficient project submission adheres to seven of the nine stated goals of the GAISE, which are listed in the literature review section. The project, while constrained to a specific dataset, is relatively open-ended, as groups can analyze various features of the data. Due to the flexibility promoted within the project, students are encouraged to display aspects of creativity in their analyses, whether it is focusing on Warner Bros. Entertainment Inc. movies, or assembling an indicator variable for if the film received a nomination for best actor or actress. Creativity often stems from the exploratory data analysis process, where groups can uncover interesting aspects to further scrutinize before beginning the analysis portion of the project. Since the majority of students will apply these concepts in their future work, statistical programming can be a useful skill to acquire, as it also provides students with a platform to individually explore datasets in the future. The most popular one in the scope of statistics is R, which has become widely used in the field. When using R to supplement the course, there are two prevailing, and competing, techniques for beginners. Students are instructed to work with either a relatively new suite of packages called the tidyverse, or base R commands that have been in use for far longer. The tidyverse was created to make coding in R more consistent, but it has less of an internet community due to its relatively young age. At the University, STA 101 classes have been taught distinctly using one or the other, creating an optimal platform to analyze the differences when using these syntaxes. Does one coding syntax encourage a certain level of creativity while simultaneously adhering to the GAISE recommendations and guidelines? That is the question this study seeks to discover through the analysis of these group projects, which are available using both base R and tidyverse methods. "],
["2-literature-review.html", "Chapter 2 Literature Review", " Chapter 2 Literature Review Source: https://arxiv.org/pdf/1903.01829.pdf The study tested to see if visualizations made by beginners are easier to decipher when created in base R or ggplot2. It did so by randomizing Coursera users to complete the same plotting task using either base R or ggplot2 and then had the learners evaluate different results crafted by their peers on a variety of visual characteristics. The users were not completely new to R, but they were still beginners, as they had just completed a course covering basic R usage in both base R and the tidyverse. The study concluded that the visualizations generated using ggplot2 were often easier to understand when creating a complex multivariate visualization. Students were more likely to uncover insights involving more complex relationships when using ggplot2, where students could use facet_grid() instead of needed two for() loops in the base R method. Concurrently, more ggplot2 assignees completed the complex visualization task. Source: https://simplystatistics.org/2016/02/11/why-i-dont-use-ggplot2/ Dr. Jeff Leek is a well-established data scientist, biostatistician, and professor at Johns Hopkins Bloomberg School of Public Health. Leek argues for using base R in plotting, and crafts his argument around his three uses for visualizations: exploratory graphs, expository graphs, and grading student work. Leek has already learned how to create visualizations in base R and can do everything in base R that can be done in ggplot2, so for him, ggplot2 does not serve a practical purpose. Leek cites examples where ggplot() is not compatible with specific visualizations, such as heatmaps, whereas base R can be far more flexible. Leek also believes that to make production-ready plots, users will need to write a large amount of code regardless of the syntax. If anything, the cleanliness of the default ggplot() settings may lead students to believe that the visualizations are suitable for production, when in reality, they would need to add more aspects. By teaching students to create visualizations in base R, students will already be accustomed to writing larger code chunks, and thus will not be phased when needing to write a few extra lines to make the visualization suitable for release. Source: http://varianceexplained.org/r/teach_ggplot2_to_beginners/ Since this post was released prior to the official release of the tidyverse, Dr. David Robinson, a well-known data scientist and instructor, focuses solely on one of its packages, ggplot2. Robinson argues that ggplot2 should be taught before base R for two reasons: To create equivalent plots in base R and ggplot(), students need an understanding loops and alternative commands. Compared to ggplot(), where students are required to use the aes() function to specify for plot aesthetics, oftentimes, base R plotting requires additional commands. Thus, with limited ggplot2 teaching, students can create interesting visualizations with seemingly advanced attributes that they would not be able to reproduce in base R. ggplot2 forces students to understand tidy data since it is required for plotting. Although this may appear to be an unnecessary tool for introductory statistics, Robinson argues that getting students in the habit of forming tidy datasets is good practice for future important functions that also require tidy datasets, such as lm(). Source: http://varianceexplained.org/r/teach-tidyverse/ As a follow up to his first post, Dr. Robinson argues for teaching the coding aspect of introductory statistics using the tidyverse syntax, which stems from his past teaching roles. Robinson claims to have been able to teach students with no prior coding knowledge on how to use the tidyverse’s facet_wrap() in 2-3 hours, which is considered a relatively advanced graphical tool. Robinson believes the role of coding within an introductory statistics course is as follows: to convince students that R is worth learning and to help them bolster their statistical knowledge. With this role in mind, Robinson writes that the tidyverse syntax encourages students to discover insights for provided datasets from the beginning, helping to both convince them of R’s importance and bolster their learning. In contrast, base R coding requires an additional understanding of its general syntax before learning tools to analyze datasets. Eventually, students need to learn base R techniques, but Robinson argues that base R can be taught in combination with the tools provided by the tidyverse, to not bog down students by general coding rules. For example, functions such as lm() and mean() can be taught as soon as students begin to grasp the basic tidyverse syntax. Robinson also argues against the teaching style that prioritizes learning conditionals and loops in these classes, since he believes that students require advanced techniques to make them effective. Source: Tidy Data by Hadley Wickham Dr. Hadley Wickham, who is considered to be the father of the tidyverse, discusses how to work with and create tidy datasets. Many popular base R functions require tidy data inputs, as well as many tidyverse commands, which were created to work symmetrically with tidy datasets. A tidy dataset lists each variable as a separate column and each observation as its own row. The rows are ordered by the first variable, measured variables are listed after fixed ones, and related ones are located in adjacent columns to ease comparison. Wickham describes the benefits of tidy data outside of its requirement for many commands. The framework was created based on his experience tackling real-world problems and datasets and then his subsequent role as a teacher. Wickham argues that most data transformation operations are easiest to perform when each variable is listed as its column. The consistent data structure allows users to start their analysis with the provided dataset instead of spending time working out the logistics of the data. Additionally, there are only a few commands needed to tidy messy data frames, called tidy tools, so once those commands are mastered, it should only take minutes to get directly into the analysis. In Wickham’s words, “Tidy tools are useful because the output of one tool can be used as the input to another.” Source: https://www.amstat.org/asa/files/pdfs/GAISE/GaiseCollege_Full.pdf (GAISE) The Guidelines for Assessment and Instruction in Statistics Education (GAISE) were first endorsed by the American Statistical Association in 2005 and then updated in 2016 to reflect changes in datasets, technology, and professional demand for statistical literacy. The GAISE is recommended for introductory statistics education, but also applies to more advanced statistics courses, as it provides six general recommendations, which already were stated in the 2005 version: Teach statistical thinking Focus on conceptual understanding Integrate real data with a context and a purpose Foster active learning Use technology to explore concepts and analyze data Use assessments to improve and evaluate student learning The GAISE also states specific goals for students in introductory statistics courses: Students should become critical consumers of statistically-based results reported in popular media, recognizing whether reported results reasonably follow from the study and analysis conducted. Students should be able to recognize questions for which the investigative process in statistics would be useful and should be able to answer questions using the investigative process. Students should be able to produce graphical displays and numerical summaries and interpret what graphs do and do not reveal. Students should recognize and be able to explain the central role of variability in the field of statistics. Students should recognize and be able to explain the central role of randomness in designing studies and drawing conclusions. Students should gain experience with how statistical models, including multivariable models, are used. Students should demonstrate an understanding of, and ability to use, basic ideas of statistical inference, both hypothesis tests and interval estimation, in a variety of settings. Students should be able to interpret and draw conclusions from standard output from statistical software packages. Students should demonstrate an awareness of ethical issues associated with sound statistical practice. Source: Infrastructure and tools for teaching statistical computing Two prominent instructors, Dr. Mine Çetinkaya-Rundel and Dr. Colin Rundel, provided guidelines here for how to use statistical programming tools in introductory statistics settings. As the statistical field continues to grow alongside programming tools, programming has morphed into a requirement, especially when handling with the practical and relevant datasets of today. Thus, the question has been shifted from a “should” to a “when” in discussing programming’s role in building a statistical education. The authors argue that students need to be exposed to programming—specifically R—early in their statistical education, but not on its own. They believe programming should be introduced in a supplemental fashion to give students the opportunity to grasp the topics covered in the traditional learning environment. R helps students bolster their understanding of the concepts discussed in lectures and also allows for an introduction to programming in a lower-level setting, so students who choose to progress through future statistics courses will not have to spend time learning basic coding concepts. In the instructors’ computation classes, they have a goal to computationally visualize something within the first 10 minutes of the first day to draw students to the importance of programming. In terms of software, the authors believe RStudio may help ease the students’ learning curve as an IDE relative to R and due to its auxiliary tools located outside of the main console. Source: The mosiac package: Helping Students to ‘Think with Data’ Using R Building off the tidyverse’s evolution, the mosaic package was created to help beginning coders develop advanced insights, as explained by the package’s authors. The authors believe that mosaic helps students to use programming in R as an asset from the start of their statistical learning. Mosaic depends on a group of packages within the tidyverse suite and contains commands such as mplot(), which allows students to create interactive plots in ggplot2. Mosaic is designed to be implemented alongside the tidyverse. Similar to how the tidyverse allows for students to start creating in R from the start, mosaic’s authors believe ”One of the keys to successfully empowering students to think with data is providing them both a conceptual framework that allows them to know what to look for and how to interpret what they find, and a computational toolbox that allows them to do the looking.” By working through examples immediately, students will begin understand R’s error messages on so they can diagnose their own code issues and lower expectations for perfect code. As a package designed for beginning R users, mosaic is also equipped with specific functions such as rflip(), which helps explain binomial situations without the use of loops. Source: https://cft.vanderbilt.edu/guides-sub-pages/team-based-learning/ “Team-based learning (TBL) is a structured form of small-group learning that emphasizes student preparation out of class and application of knowledge in class.” Proponents of TBL cite studies concluding that students learned more when placed in TBL settings compared to when they worked individually. TBL may be more beneficial for students because it forces the individual team members to debate amongst each other, thus bolstering or modifying their current knowledge to better comprehend the topic. Source: Final Project Assignment Documents for Each Class Overall, there were no significant changes in the STA 101 final project assignment document over the course of the 2013-2016 academic years. However, there were still small alterations that may have influenced the project submissions. For final projects completed in 2014 and onwards, student groups were placed in a situation at Paramount Pictures at a hypothetical job, whereas for Fall 2013 students, they were merely assigned the task at hand without the additional setting. Fall 2013 student groups were also not tasked with the audience score prediction component for a movie, but the covariate created in this study was not utilized in the analysis. Perhaps most importantly, though, the Fall 2013 final project assignment document features a small alteration in the grading section, where Dr. Çetinkaya-Rundel details the factors important in determining the final project grades. In the Fall 2013 semester, one section is titled “Creativity and Critical Thought”, compared to the document for more recent semesters, where the section is titled, “Critical Thought”. Although it is a minute wording discrepancy, the stating of the direct importance of creativity relative to student grades may have provided an extra incentive for Fall 2013 project groups when conducting their EDAs. "],
["3-data.html", "Chapter 3 Data 3.1 Final Project 3.2 Student Groups 3.3 Dataset Background", " Chapter 3 Data 3.1 Final Project The final project simulates a complete data analysis using relevant techniques covered throughout the STA 101 curriculum. The final project is the second of two that groups complete, but it differs drastically from the frst. Whereas the first project focuses on statistical inference and the dataset description, the second one is more comprehensive in its requirements, with specifications for EDA and regression sections, as well as more creativity to address the final project’s directives. In the final project, student groups simulate a task at a new music studio where their boss hypothetically assigns two goals: the boss wants to learn about the attributes that make a movie popular and also something new about movies. The final project contains five components—an introduction, a univariate analysis, a bivariate analysis, a multiple regression for predicting audience scores, and a conclusion. The regression section is relatively constant amongst groups in determining an optimal regression. However, in the univariate and bivariate analyses, student groups can explore a variety of different options, often differentiating between the relative strengths of the projects. The student project dataset has been nearly constant throughout this analysis, and it tracks a random sample of American movies released since 1970. The student project dataset contains between 25 and 32 variables summmarizing the movie’s general characteristics, such as runtime, genre, and production studio, award trackers, such as best picture, best actor, best actress and best director indicator variables, as well as data from an online film review website (Rotten Tomatoes) and an online movie database (IMDB). Although variables such as the producing studio, the month and day of the week of both the theatre and DVD releases, IMDB rating (out of 10) and audience rating on Rotten Tomatoes are not included in the original 2013 dataset, student groups were provided with a sufficient amount of potential variables to analyze. The student project dataset’s most recent codebook, directly copied from the Spring 2016 project assignment, is available in the appendix. 3.2 Student Groups Students remained in the same groups they were assigned at the beginning of the semester since the groups were crafted based on the results of both a pre-test and a survey. Both the pre-test and the survey were geared toward understanding each individual’s statistical background and literacy upon entering the course. Students worked through each lab assignment together, which consisted of exercises in R, and were encouraged to study together for exams as well. Student-based learning has been supported by studies showing that students absorb more when placed in smaller groups compared to when they worked individually. This may be due to increased collaboration, with debate amongst the team members that usually reinforces their understandings of the concepts covered in the course. Because of the large class sizes of STA 101, which total at least 70 students, professors utilize team-based learning techniques to help the students learn outside of a large lecture situation. 3.3 Dataset Background The dataset has been manually compiled from 205 STA 101 final group projects spanning the 2013-2016 academic years. 13 data entries were discarded since the complete project submissions could not be recovered. The projects’ contents are located on Duke’s Sakai sites of seven different classes, six of which were taught by Dr. Cetinkaya-Rundel. However, the professor themself does not affect much of the R learning over the course of the semester, since it occurs within student’s labs, which are led by teaching assistants. Although there may be some slight instructor effects on coding abilities, the teaching assistants are the primary educators of R, and they generally change each semester. Therefore, some sections may have stronger grasps of coding for the final project, but it is likely to be minimal since teaching assistants are apprised of the upcoming week’s content via weekly meetings with the professor. In the case of the final project, the submitted file(s) were in either R Markdown or an R script. The dataset utilized in this paper primarily focuses on actions taken by groups within the univariate and bivariate portions of the projects. In doing so, the the dataset contains variables summarizing relative creativity measures, as well as the projects’ depth. Explanations of each variable will be available in the following chapter. "],
["4-methods.html", "Chapter 4 Methods 4.1 Creativity 4.2 Depth 4.3 Multivariate Visualization", " Chapter 4 Methods Since 98 percent of the projects were submitted either as an R script or R Markdown document, the student project code could be analyzed directly on their downloaded submission documents. Each project was examined and coded as either a 0, if the attribute was missing, or 1, if it was present, for 16 variables. The remaining three covariates identified the student projects by grade, index, and class. Due to privacy concerns, since the project submissions often contained the members of the project group, each student project was provided with an index, and the names of the students in each group were removed from their submission document. For the dataset utilized in this thesis, projects can solely be identified by their assigned index. A separate dataset serves as a link between the individual projects and their titles. The first few rows of the dataset compiled in this project are available below. head(project) # A tibble: 6 x 22 index grade sem r_rmd tidyverse create_new_var change_var sub_analysis &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 1 87.1 Fall… .r base R no no yes 2 2 89.2 Fall… .r base R yes no yes 3 3 80.2 Fall… .r base R no no yes 4 4 87.2 Fall… .r base R yes no yes 5 5 80.4 Fall… .r base R no no yes 6 7 90.2 Fall… .r base R no no no # … with 14 more variables: sub_data &lt;chr&gt;, viz_mult_make &lt;chr&gt;, # viz_mult_interpret &lt;chr&gt;, eda_theme &lt;chr&gt;, rel_data &lt;chr&gt;, # slr_fit &lt;chr&gt;, mlr_fit &lt;chr&gt;, mlr_check_cond &lt;chr&gt;, prediction &lt;chr&gt;, # ht &lt;chr&gt;, ht_check_cond &lt;chr&gt;, creative &lt;int&gt;, theme &lt;int&gt;, # multiviz &lt;int&gt; The student projects were not compiled into PDF or HTML files to confirm that the code worked, since it was a near-impossible task to determine which version of R packages the students utilized, as some of these commands are now defunct in the most recent versions of the packages. Because of this decision, this analysis operates under the assumption that the code produced the desired results in each project and did not require further debugging. The contents of the student project code were still analyzed for clarity, as well as creativeness, depth, and multivariate visualizations through the 16 indicator variables. They were analyzed for these aspects specifically since they are prominently emphasized throughout the GAISE. Code snippets will be provided in the following chapter to display examples that scored a one for distinct covariates. index: Project ID grade: Score on final project sem: Semester course taken r_rmd: Was the submission an R script (with prose of the project turned in as a Word document) or was the submission an R Markdown file? tidyverse: Project used &quot;tidyverse&quot; or &quot;base R&quot; syntax create_new_var: Students created a new variable based on existing variables, &quot;yes&quot; or &quot;no&quot; change_var: Students changed existing variables, &quot;yes&quot; or &quot;no&quot; sub_analysis: Students performed a subgroup analysis, &quot;yes&quot; or &quot;no&quot; sub_data: Students used data subsets for the entire project, &quot;yes&quot; or &quot;no&quot; viz_mult_make: Students employed visualizations with at least three variables, &quot;yes&quot; or &quot;no&quot; viz_mult_interpret: Students properly interpreted their 3+ variable visualization, &quot;yes&quot; or &quot;no&quot; eda_theme: Students used a consistent theme throughout their project, &quot;yes&quot; or &quot;no&quot; rel_data: Students supplemented their project theme with relevant data, &quot;yes&quot; or &quot;no&quot; slr_fit: Students fitted a simple linear regression, &quot;yes&quot; or &quot;no&quot; mlr_fit: Students fitted a multiple linear regression, &quot;yes&quot; or &quot;no&quot; mlr_check_cond: Students properly checked the conditions for their multiple linear regression, &quot;yes&quot; or &quot;no&quot; prediction: Students used their multiple linear regression to predict a movie’s audience score, &quot;yes&quot; or &quot;no&quot; ht: Students performed a hypothesis test, &quot;yes&quot; or &quot;no&quot; ht_check_cond: Students correctly checked the conditions for their hypothesis test, &quot;yes&quot; or &quot;no&quot; 4.1 Creativity The creativity metric seeks to encapsulate anything students coded that was not directly specified in the instructions but provided a purpose in their projects. The metric’s possible scores range from 0 to 4, as a project is scored with a single point for each of the following: Creation of new variable(s) based on existing variables Transformation of existing variables Existence of a subgroup analysis The use of a subset of the dataset for all steps of the project In the case of the student group projects utilizing the tidyverse syntax, groups were still given scores of ones if they satisfied these conditions in Base R form. While rare, two (NEED TO CONFIRM) groups in labs taught in the tidyverse created or transformed covariates using Base R syntax, which was likely due to alternative resources, such as Stack Overflow, that at the time, did not contain many tidyverse solutions. Now, though, as the tidyverse’s popularity continues to grow, more online resources incorporate and promote tidyverse solutions. 4.1.1 Creation of New Variable(s) The creation of a new variable(s) is defined as any data manipulation throughout the EDA process where student groups compose a previously non-existing covariate. As an example, one project created a new variable tracking if a movie had won any of the following awards: best picture, best actor, best actress, or best director, and that project had this variable coded as “yes.” In order to score a 1, the student project also had to utilize the new variable within an aspect of their analysis. This condition filtered for groups that created unnecessary covariates. However, a score of 1 would be valid if the group did not use the variable in the inference or regression sections, but did explore the covariate in their EDA. 4.1.2 Transformation of Existing Variables Although related to the above covariate, the transformation of existing variables did not qualify as creating new variables, or vice versa. In this situation, a project would score a one if the student group mutated a variable already existing within the dataset, generally to highlight certain cases. For instance, a few project groups decided to change mpaa_rating to either “R” or “Other,” if the movie was not rated R. Similar to the requirements for scoring a one for the creation of new variable(s) covariate, the mutation was required to be employed to some end, as groups would have to provide at least a cursory analysis of the newly-mutated variable to score a one. A distinction between scoring a one for this covariate and one for subsetting the dataset or conducting a subgroup analysis is that filtering the dataset for just entries that cover a portion of levels within a specific variable would qualify as a part of either a subgroup analysis or data subset, but not this covariate. Also, converting a factor variable that could be potentially read in as one when loading the dataset did not qualify as a mutation of an existing variable for this study. 4.1.3 Existence of Subgroup Analysis The presence of a subgroup analysis was measured in regards to creativity. Projects that received a one analyzed portions of the data during their EDA process. Groups could use an assortment of commands to satisfy a score of a 1, such as a normal boxplot, five-number summary of a specific variable within the movies dataset, or a subsetting with a corresponding numerical or graphical analysis. As an example, a project receiving a one for this category may have analyzed how the audience ratings for R rated movies compared to that of PG-13 movies in their bivariate analysis. 4.1.4 Use of a Data Subset for Project’s Entirety Although the use of a data subset covariate may seem similar to the one above, this variable received a one for a different aspect of the final group projects. Here, student groups are not just using the provided movies dataset for their EDA, inference, and regression—they are intentionally focusing on a few characteristics of the movie dataset. Student projects were not required to employ the same subsetted data throughout the entire analysis, but they did have to analyze related aspects of the movies dataset to qualify for a one. For example, one student group scrutinized solely PG-13 rated movies for their final project, while another used the PG-13 rated movies subset for the EDA, PG-13 movies released after 2000 for the inference, and then the same PG-13 rated movies subset utilized in the EDA process for their regression analysis. 4.2 Depth Focus on students’ understanding of key concepts, illustrated by a few techniques, rather than covering a multitude of techniques with minimal focus on underlying ideas. The depth metric measures the level of depth of the analysis, both in terms of the statistical methods utilized and in terms of story-telling. Since the GAISE advises instructors to focus on students’ comprehension of important basic concepts rather than covering a multitude of topics with little breadth, the depth metric qualifies the student groups’ understanding of the subjects covered in the project. The metric ranges from 0-2 and is scored with 1 point for each of the following: Presence of consistent theme throughout the project Use of relevant data The depth metric was created to qualify findings from the creativity score, to confirm that the syntax producing the more creative student projects also were of the same (or better) quality. Although creativity is imperative in these final projects, student groups also cannot skip parts of the data analysis cycle. 4.2.1 Consistent Theme In the world of data science, story-telling is such an important aspect, just as story-telling is designed to be for the STA 101 final group projects. A strong final project requires a story: a leading question, initial findings, subsequent analyses, and conclusion, all formed around a specific theme. Although this covariate’s scoring was subjective, the requirements for final projects to score a one were similar to those defining the creativity metric. To receive a one, student groups clearly linked the steps in their analysis, often choosing to focus on a few aspects within the entire movie dataset. For instance, analyzing the impact of movie ratings on audience scores would qualify as a sufficient theme, but referencing an assortment of different predictors would not register as one. 4.2.2 Presence of Relevant Data Another subjective variable, the presence of relevant data was formed to complement the consistent theme covariate. To receive a one for this variable, student groups were required to sufficiently use R to create insights surrounding their chosen theme(s). The covariate addresses the issue that projects may have interesting themes but lack the analysis and coding quality to supplement their project. As an example, an aspect of a group project that would have scored a one for this category would have displayed the correlation coefficient between two numerical variables instead of plotting them together and failing to acknowledge the figure in the project submission. If the majority of the coding could be employed to support the final project, the project group received a one. 4.3 Multivariate Visualization The multivariate visualization metric accounts for both the presence and the insights derived from visualizations with at least three variables. Especially when using a movies dataset with many binary variables student groups often analyzed, visualizations with at least three variables and their subsequent interpretations can supplement important insights uncovered in the final projects. Also, the GAISE highlights the significance of teaching students how to interpret multivariate visualizaitons. “When students leave an introductory course, they will likely encounter situations within their own fields of study in which multiple variables relate to one another in intricate ways. We should prepare our students for challenging questions that require investigating and exploring relationships among more than two variables (GAISE).” The metric ranges from 0-2 and is scored with 1 point for each of the following: Presence of a visualization with 3+ variables Interpretation of the multivariate visualization Although the two variables that constitute the multivariate visualization metric are related, as a project could not score a one for the interpretation if it did not contain a multivariate visualization, the presence of the visualization did not imply that there was a useful interpretation in the project write-up. 4.3.1 Presence of a Visualization with 3+ Variables The presence of a visualization with at least three variables is an objective variable simple to when dissecting final project submissions. Groups nearly always utilized colors to display a third variable along with two numerical ones on the x- and y-axes. To receive a score of a one, projects were required to produce a graphical output with at least three aesthetics. For instance, some student groups created scatterplots between the critic and audience scores for all the movies in the given dataset with different colors for movies that won best picture at the Oscar’s that year. 4.3.2 Interpretation of Multivariate Visualization The interpretation of a multivariate visualization is not a completely objective variable. A project containing an incorrect or insufficient interpretation of its multivariate visualization would not receive a score of a one. By insufficient, the project does not need to address every aspect of the visualization, but it needs to discuss a key insight to help bolster the overall final project. "],
["5-results.html", "Chapter 5 Results 5.1 Creativity Metric 5.2 Depth Metric 5.3 Multivariate Visualization Metric", " Chapter 5 Results Both numerically and graphically, the student projects dissected in this study using the tidyverse syntax scored higher on all three of the developed metrics. tidyverse projects are much more prevalent in the upper levels of the three variables, and their means and standard deviations are significantly different as well. 5.1 Creativity Metric Despite there being only 82 base R projects recorded to the 123 tidyverse projects, there more base R projects scored a 0 or 1 on the creativity metric than those using the tidyverse syntax. Overall, there was a single project that scored a perfect four out of the 205 total projects, and the majority of the projects scored a one or two in the creativity metric. However, within the tidyverse projects, more than half (56.1 percent) registered at least a two on creativity, compared to just 20.7 percent of base R projects. The average creativity scores and corresponding standard deviations for projects utilizing the two syntaxes are available below as well: Syntax Mean SD Base R 1.1 0.6 Tidyverse 1.7 0.8 Syntax Mean Standard Deviation Base R 1.1 0.6 Tidyverse 1.7 0.8 FOR MINE: Which table should I use? One has SD as Standard Deviation The following subsections will contain a comparison of base R and tidyverse student projects for each of the four variables combined to form the creativity metric, as well as potential reasons for the outcomes. 5.1.1 Creation of New Variable(s) Out of the four variables that form the creativity metric, the starkes difference between projects employing the two syntaxes was within the creation of new variable(s) covariate. Nearly half of all final projects using the tidyverse syntax featured a creation of a new variable, whereas less than a quarter of base R projects did. tidyverse create_new_var n proportion base R yes 18 24.0% tidyverse yes 59 50.0% This difference may be due to the ease in utilizing the tidyverse’s mutate() function, which allows users to create new variables using a single command. In base R, students are instructed to use $ notation, which may be harder to grasp due to issues with variable selection with $ and its usage in other base R tasks outside of just creating new variables. 5.1.2 Transformation of Existing Variables While more than 75 project groups created new variables, far less opted to mutate existing ones in the movies dataset. Because the counts for both base R and tidyverse projects were lower, the resulting proportions were also much smaller. Regardless, there were more projects using the tidyverse syntax that mutated existing variables. tidyverse change_var n prop base R yes 2 2.7% tidyverse yes 9 7.6% The difference in proportions was not nearly as significant as it was for the creation of new variables and only differed marginally. This limited difference can be attributed to two factors. First, with the option to create their own variables, groups may not find transforming existing variables as appealing. Second, the mechanism to do so does not differ dramatically between the two syntaxes. For comparison, an example of changing an existing studio variable to “Warner Bros. Studios” or “Other” is listed in both Base R and the tidyverse: Base R: movies$studio &lt;- if_else(movies$studio == &quot;Warner Bros. Pictures&quot;, &quot;Warner Bros. Pictures&quot;, &quot;Other&quot;) Tidyverse: movies &lt;- movies %&gt;% mutate(studio = (if_else(studio == &quot;Warner Bros. Pictures&quot;, &quot;Warner Bros. Pictures&quot;, &quot;Other&quot;)) 5.1.3 Existence of Subgroup Analysis Out of all the covariates forming the creativity metric, the subgroup analysis was the most popular one satisfied for both base R and tidyverse projects. 93.5 percent of tidyverse projects performed a type of subgroup analysis, while more than 3/4 of base R projects did. tidyverse sub_analysis n prop base R yes 65 86.7% tidyverse yes 115 97.5% The popularity of this aspect within group projects may be explained by the copious ways student groups could perform a subgroup analysis. However, subgroup analyses may be easier to perform in the tidyverse due to the presence of the group_by() command, which is usually one of the most popular functions for beginning R users in the tidyverse. In contrast, base R’s by() function is not nearly as well-known. 5.1.4 Use of a Data Subset for Project’s Entirety The use of a subset of the provided movies dataset for the entire final project was also significantly more popular amongst tidyverse projects, as more than 15 percent of student projects using the tidyverse satisfied a score of a one for this covariate, compared to less than 5 percent of all base R projects. tidyverse sub_data n prop base R yes 4 5.3% tidyverse yes 20 16.9% Since there is little difference between the tidyverse’s filter() and base R’s subset() functions, this discrepancy might not be able to be explained by in an obvious manner. Perhaps, though, student groups using the tidyverse may have been more encouraged to utilize data subsets throughout their projects more often than those in base R because other aspects of EDA have been performed more frequently in tidyverse projects, so those groups may have gained additional insights that led them to use a data subset that base R project groups did not discover. 5.2 Depth Metric Although the depth metrics scores between final projects that employed base R syntax compared to those using the tidyverse do not provide a similar discrepancy as the creativity score, there is still a considerable difference in the depth metric distributions between projects of the two syntaxes. 48.8 percent of the projects using the tidyverse syntax scored a perfect two in the depth metric compared to 34.1 percent of base R projects, while the extreme majority of base R projects scored a 0 or 1 in the depth metric. Overall, most projects scored a one. The average depth scores and corresponding standard deviations for projects utilizing the two syntaxes are available below as well: Syntax Mean SD Base R 1.2 0.7 Tidyverse 1.4 0.7 FOR MINE: Which table should I use? One has SD as Standard Deviation Syntax Mean Standard Deviation Base R 1.2 0.7 Tidyverse 1.4 0.7 5.2.1 Consistent Theme Within the theme metric, the variable tracking the presence of a consistent theme showcased a larger difference in proportions between base R and tidyverse student projects. Compared to base R projects, where 57.3 percent boast a consistent theme, 71.5 percent of all tidyverse projects maintain consistency theme-wise. tidyverse eda_theme n prop base R yes 47 62.7% tidyverse yes 88 74.6% The difference in proportions may potentially be attributed to the prevalence of select() and filter() within the tidyverse syntax, which allows users to choose specific columns within a data that satisfy a certain criteria, compared to base R, when student groups commonly utilized square brackets to provide those same criteria. 5.2.2 Presence of Relevant Data Proportions for the presence of relevant data covariate were very similar, with just a 4.4 percent difference in proportions (64.2 for tidyverse compared to 59.8 for base R projects) between projects using the two syntaxes. tidyverse rel_data n prop base R yes 49 65.3% tidyverse yes 79 66.9% The presence of relevant supporting data should not be greatly impacted by the particular coding syntax student groups employed, which may explain the small difference in proportions for this variable. 5.3 Multivariate Visualization Metric Between projects using the two different syntaxes, the most significant difference in any of the three metrics occurred within the multivariate visualization metric, where just one final project in base R even displayed a plot containing at least three different variables. The majority of all projects did not include multivariate visualizations, but projects using the tidyverse syntax were more popular within higher scores of the metric in general, with 13 percent scoring a perfect two, while no projects in base R reached the same score. The average multivariate visualization scores and corresponding standard deviations for projects utilizing the two syntaxes are available below as well. Although the statistics do not represent the difference in the metric between projects of the two syntaxes, there is still a distinct divide. Syntax Mean SD Base R 0.0 0.1 Tidyverse 0.4 0.7 FOR MINE: Which table should I use? One has SD as Standard Deviation Syntax Mean Standard Deviation Base R 0.0 0.1 Tidyverse 0.4 0.7 5.3.1 Presence of a Visualization with 3+ Variables Only one project coded in solely base R displayed a visualization with at least three variables, compared to 30 tidyverse projects. Percentage-wise, too, the tidyverse projects were more likely to contain a multivariate visualization. tidyverse viz_mult_make n prop base R yes 1 1.3% tidyverse yes 30 25.4% These results may be due to the differences in base R’s plot() function relative to the tidyverse’s ggplot(). Whereas plot() requires extra commands to add graphical aesthetics besides x- and y-variables, the aes() command embedded within ggplot() provides an easy platform for tidyverse users to employ other aesthetics besides just the x- and y-variables. For example, code is listed below that would satisfy a score of one when using the two syntaxes. Base R: movies.color &lt;- rep(&quot;pink&quot;, length(movies$best_pic_nom)) movies.color[movies$best_pic_nom == &quot;yes&quot;] &lt;- &quot;blue&quot; plot(audience_score ~ critics_score, col = movies.color, data = movies) legend(col = c(&quot;pink&quot;, &quot;blue&quot;)) Tidyverse: ggplot(data = movies, aes(x = critics_score, y = audience_score, color = best_pic_nom)) + geom_point() FOR MINE: This code is correct, right? 5.3.2 Interpretation of Multivariate Visualization No student project using solely base R interpreted a multivariate plot, whereas 13 percent of projects utilizing the tidyverse did. Although the proportion satisfying a score of a one is not very high, more than half of tidyverse projects that formed a visualization with at least three variables (16 out of 30) contained sufficient intepretations of the outputs. tidyverse viz_mult_interpret n prop tidyverse yes 16 13.6% Theoretically, the difference in proportions between projects primarily using base R compared to the tidyverse should not drastically differ. However, since there were more tidyverse projects that contained multivariate plots, there was bound to be a difference in this covariate. In general, though, the plots should not deviate for interpretation, though some users may find comfort in viewing graphs provided by their most commonly-used syntax. "],
["6-educational-resources.html", "Chapter 6 Educational Resources 6.1 Infer Vignettes 6.2 Lab Enhancements", " Chapter 6 Educational Resources After analyzing the retrospective study, we provided two resources designed for statistical instruction to reflect our insights in favors of the tidyverse syntax. We altered current STA 101 labs to further adhere to the GAISE manual and provided two code samples with explanations for infer, an R package created to perform inference tasks using a tidy framework. 6.1 Infer Vignettes Currently, the tidyverse contains packages to clean, mutate, model and visualize data. However, the tidyverse syntax cannot be used to perform inference tasks. Due to the popularity and demand for the tidyverse framework, a group of professors created a relatively new package titled infer, which is fashioned as the tidyverse solution to inference. Like packages such as dplyr and ggplot2, infer relies on a few commands to execute a variety of tasks and benefits from the piping structure used throughout the tidyverse. Unfortunately, infer does not presently include detailed examples that showcase the package, and when potential users search for package resources, they are left nearly empty-handed. Therefore, we decided to write two vignettes—longer code samples embedded within data analysis stories—to provide infer users with vivid examples and explanations for proper usage of the package. By inference, the two primary tasks are performing hypothesis tests and creating confidence intervals—hence a vignette for each. The vignettes also utilize separate aspects of the same dataset, to provide users the comfort of a consistent data source while exposing them to tasks using both numerical and categorical variables. The complete vignettes are available in the Appendix. 6.2 Lab Enhancements Based on the results gleaned from analyzing the student project data from introductory statistics courses at Duke University, we decided to fully apply tidyverse syntax and methods to introductory statistics labs. OpenIntro Statistics is an open-source textbook approved for use at the undergraduate level by the American Institute of Mathematics, and the labs accompanying OpenIntro textbooks are available online and are used by students at many institutions, including at Duke University. These labs have been updated in 2016 to incorporate tidyverse syntax for data visualization and wrangling, though statistical inference still relied on Base R syntax. As part of this project, we have updated the code introduced in the labs to fully leverage the Tidyverse ecosystem, including the infer package for tidy statistical inference. Since the most recent update of the labs to incorporate tidyverse syntax, recommendations around introducing data visualization with ggplot2 have changed. Previous practice used the qplot() (quick plot) function, which has a simpler API than the ggplot() function, but is more cumbersome to produce complex multivariate visualizations with. With this update, we have completely abandoned the use of qplot() and replaced it with ggplot(), resulting in changes in associated code and narrative. Two main reasons for this change are the existence of plethora of resources for debugging ggplot() as well as ease of expansion to complex visualizations. Another major update was in the labs that focus on statistical inference, i.e. hypothesis testing and confidence intervals. Previous version of the labs used a custom function called inference() from the oilabs package, the R package used to supplement OpenIntro. This function, designed with the best intentions in mind for highlighting the unified nature of statistical inference across various hypothesis tests and confidence intervals introduced in introductory statistics curricula, over time morphed into a function that is too extensive for efficient debugging and too customized for use beyond the introductory statistics classroom. The infer package, released in 2018, was heavily inspired by the inference() function, but significantly improved the API for tidy statistical inference and tied it closely to how we recommend introducing statistical inference in introductory statistics curricula. The goal of this package “is to perform inference using an expressive statistical grammar that coheres with the tidy design framework,” as per its R documentation. For instance, here is code for generating a two-sided hypothesis test using the two methods, with the inference() function first. inference(y = y_variable, x = x_variable, data = data, statistic = &quot;mean&quot;, type = &quot;ht&quot;, null = 0, alternative = &quot;twosided&quot;, method = “theoretical&quot;) obs_diff &lt;- data %&gt;% specify(dependent ~ independent) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;yes&quot;, &quot;no&quot;)) null &lt;- data %&gt;% specify(dependent ~ independent) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;yes&quot;, &quot;no&quot;)) null %&gt;% get_p_value(obs_stat = obs_diff, direction = &quot;two_sided&quot;) And here is an example of code creating a 95 percent confidence interval using inference() and infer, respectively. inference(y = response, data = data, statistic = &quot;proportion&quot;, type = &quot;ci&quot;, method = &quot;theoretical&quot;, success = &quot;yes&quot;) data %&gt;% specify(formula = text_ind ~ NULL, success = &quot;yes&quot;) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;prop&quot;) %&gt;% get_ci(level = .95) The labs focusing on statistical inference have thus been updated with the current infer syntax in order to provide students with a workflow they can extend outside of their classroom setting alongside the tidyverse, as well as one with available online resources. A few of the labs also featured datasets that have either been out of use for the past few years and will continue to be considered outmoded, were convoluted and required supplementary information, or intentionally or unintentionally promoted gender stereotypes. These datasets, and the corresponding labs, were updated with more robust and interesting material, as summarized in the table below. The datasets were analyzed prior to insertion to affirm that they would have the bandwidth to seamlessly fit the particular focus of the labs. Previous Dataset Reason for Change New Dataset Body Dimensions Focuses on weight comparison across binary genders Fast Food Nutritional Facts Atheism and Religion Unverified Dataset Youth Risk Behavior Surveillance System Baseball Required further dataset explanation Human Freedom Index North Carolina Births Dated + Not relevant for most undergrads Youth Risk Behavior Surveillance System "],
["conclusion.html", "Conclusion", " Conclusion Due to the discrepancies in creativity, depth, and multivariate visualization scores between students projects using base R and others employing the tidyverse syntax, we recommend that the tidyverse syntax should be the primary syntax when using R as a supplement for introductory statistics courses. Although the sample is limited by solely analyzing Duke’s STA 101 final projects, the standardization of STA 101 classes provides an optimal baseline for comparison. Another potential source of bias, the project assignment document, can be nullified by the lack of wording differences since the Fall 2013 document (a base R class). As such, since there was shown to be higher scores in the three metrics for projects using the tidyverse syntax, the project language is not considered to be a confounding variable. Since we could not find a significant confounding factor, we can attribute the distinctions in creativity, depth, and multivariate visualization scores to the R syntax. Additionally, since the final projects were randomly scored by course, and then later checked, we are confident that there was no bias in the coding of the indicator variables. We confirmed tough scoring situations through collaboration between Mr. Feder and Dr. Çetinkaya-Rundel, and based on the guidelines outlined in Methods, the differences between scoring a one and zero for the various indicator variables should be distinct. We encourage instructors to teach introductory R using the tidyverse syntax, as well as the inclusion of infer for inference tasks. We believe that the tidyverse’s consistency encourages students to produce more creative and higher quality work while tightly adhering to the GAISE. We hope the educational resources created as a result of this study will have far-reaching impacts within the statistical community and will become staples for R users in the future. If you feel it necessary to include an appendix, it goes here. --> "],
["A-the-first-appendix.html", "A The First Appendix", " A The First Appendix This first appendix includes all of the R chunks of code that were hidden throughout the document (using the include = FALSE chunk tag) to help with readibility and/or setup. In the main Rmd file library(thesisdowndss) library(servr) In Chapter ??: "],
["B-the-second-appendix-for-fun.html", "B The Second Appendix, for Fun", " B The Second Appendix, for Fun "],
["references.html", "References", " References "]
]
