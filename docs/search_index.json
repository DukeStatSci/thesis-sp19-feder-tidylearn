[
["index.html", "Evaluating Student Creativity, Depth and Multivariate Visualizations of Data Analysis projects based on R Syntax and Packages Abstract Acknowledgements Dedication", " Evaluating Student Creativity, Depth and Multivariate Visualizations of Data Analysis projects based on R Syntax and Packages Benjamin Feder May 2019 Abstract Programming has become an essential component of introductory statistics, as students use R to explore general concepts. Currently, there are two methods of teaching R for beginning statisticians, but not much literature on how they affect student comprehension and analysis. We analyzed 205 final projects written using the two syntaxes for an introductory statistics course at Duke University from the 2013-2016 academic years, creating a variety of indicator variables to measure their creativity, depth and the complexity of multivariate visualizations. Student projects using the tidyverse syntax were found to score significantly higher on all three metrics, suggesting instructors should employ the tidyverse when teaching beginning statistics. Based on these results from the retrospective study, we created resources designed for future use in statistical instruction. Keywords: Introductory statistics, Education, Tidyverse, Creativity, Depth, Multivariate visualizations, Retrospective study Acknowledgements I thank my advisor, Dr. Mine Çetinkaya-Rundel for her immense dedication and support in supervising this project. I could not have done this without her, let alone obtain a legitimate dataset to perform a comparative analysis. I also thank Dr. Victoria Ellison for her essential advice, and the Department of Statistical Science for providing me with the tools to complete this project. Most of all, I thank my family and friends for their love and belief in me for the past 21 years. Dedication I dedicate my thesis to my past students for whom I have been a teaching assistant for their enthusiasm that gave me the motivation to complete this thesis. This project was approved by the Duke University Institutional Review Board, 2019-0130 "],
["1-introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction STA 101 is the primary introductory statistics course at Duke University, where students are assumed to have entered the class without any statistical knowledge. The majority of students enrolled in the course do not plan on enrolling in future statistics curricula, focusing the course on applications of statistics, as students learn how to relate STA 101’s concepts to their future works. At the beginning of the course, the students are divided into groups where they complete assignments throughout the course together. The class is split into seven units, and every section has at least one lab, taught in R, to bolster the learning segment. For introductory statistics education, the Guidelines for Assessment and Instruction in Statistics Education (GAISE) sets quality and scope standards, as it provides a set of general recommendations, as well as specific goals to be accomplished by the course’s completion. With its updated version released in 2016, the GAISE, which is endorsed by the American Statistical Association, recommends that students use programming, if accessible, to explore real-world examples of concepts covered in the classroom (Carver et al., 2016). To conclude the STA 101 semester, students display their grasp of the concepts by completing a group project conducted in R. A sufficient project submission adheres to seven of the nine stated goals of the GAISE, which are listed in the literature review section. The project, while constrained to a specific dataset, is relatively open-ended, as groups can analyze various features of the data. Due to the flexibility promoted by the project assignment, students are encouraged to display aspects of creativity in their analyses, whether it is focusing on Warner Bros. Entertainment Inc. movies, or assembling an indicator variable tracking if a member of the film received a nomination for best actor or actress. Creativity often stems from the exploratory data analysis process, where groups can uncover interesting aspects to further scrutinize before beginning the analysis portion of the project. Since the majority of students will apply these concepts in their future work, statistical programming provides students with a platform to individually explore datasets in the future. When using R as a course supplement, there are two prevailing and competing techniques for beginners (Robinson, 2017, Leek (2016)). Students are instructed to work with either a relatively new suite of packages called the tidyverse or base R commands that have been in use for far longer. The tidyverse was created to make coding in R more consistent, but it does not contain as many internet resources, such as debugging responses on Stack Overflow, as base R. At Duke University, the programming aspect of STA 101 classes have been taught in either base R or the tidyverse syntax, creating an optimal platform to diagnose the direct affects of the syntax. Through the analysis of R code from STA 101 final group projects, we hope to uncover if one programming syntax encourages a more advanced level of creativity while simultaneously adhering to the GAISE recommendations and guidelines. A study released March 3, 2019 attempted to uncover the answer to a similar question, as it studied the difference in visualization quality between base R plots and ggplot2, a package within the tidyverse, for beginning R programmers (Myint, Hadavand, Jager, &amp; Leek, 2019). Although the evaluation favored visualizations crafted using ggplot2, it focused on the output of the code, rather than the code quality. This study concerns the code itself, and whether beginning coders were encouraged to be more creativity and produce higher-quality final projects based on the syntax. "],
["2-literature-review.html", "Chapter 2 Literature Review", " Chapter 2 Literature Review (Myint et al., 2019) The study sought to determine if visualizations made by beginners are easier to decipher when created in base R or ggplot2. It did so by randomizing Coursera users to complete a study-wide plotting task using either base R or ggplot2, and then had the learners evaluate visualizations crafted by their peers on a few visual characteristics. The users were not completely new to R, but they were still beginners, as they had just completed a course covering basic R usage in both base R and the tidyverse. The study concluded that the visualizations generated using ggplot2 were often easier to understand when creating a complex multivariate visualization. Students were more likely to uncover insights involving more complex relationships when using ggplot2, where students could use facet_grid() instead of needing the two for() loops for the base R method. Concurrently, more ggplot2 assignees completed the complex visualization task. This has been the only well-known study conducted that analyzed the differences between the tidyverse and base R for introductory courses. Other arguments have been made on data science blogs favoring base R or the tidyverse when teaching beginning statistics. The following source was written by a proponent of base R. (Leek, 2016) Dr. Jeff Leek is a well-established data scientist, biostatistician, and professor at Johns Hopkins Bloomberg School of Public Health. Leek argues for using base R in plotting, and crafts his argument around his three uses for visualizations: exploratory graphs, expository graphs, and grading student work. Leek believes he has mastered visualizations in base R and can do everything in base R that can be done in ggplot2. For him, ggplot2 does not serve a practical purpose. Leek also cites examples where ggplot() is not compatible with specific visualizations, such as heatmaps, whereas base R can be far more flexible. Leek also believes that to make production-ready plots, users need to write a large amount of code regardless of the syntax. If anything, the cleanliness of the default ggplot() settings may lead students to believe that the visualizations are suitable for production, when in reality, they would need to add more aspects. By teaching students to create visualizations in base R, students will already be accustomed to writing larger code chunks, and thus will not be phased when needing to write a few extra lines to make the visualization suitable for release. Leek’s blog post came in response to the writings of some pro-tidyverse instructors, such as Dr. David Robinson, who is an active supporter of using the tidyverse to help teach introductory statistics. (Robinson, 2014) Since this post was released prior to the official release of the tidyverse, Robinson, a well-known data scientist and instructor, focuses solely on one of its packages, ggplot2. Robinson argues that ggplot2 should be taught before base R for two reasons: To create equivalent plots in base R that can be easily done using ggplot2, students require an understanding loops and alternative commands. Compared to ggplot(), where students are required to use the aes() function to specify visualization aesthetics, oftentimes, base R plotting requires additional commands. Thus, with limited ggplot2 teaching, students can create interesting visualizations with seemingly advanced attributes that they would not be able to reproduce in base R. ggplot2 forces students to understand tidy data as it is required. Although this may appear to be an unnecessary tool for introductory statistics, Robinson argues that getting students in the habit of forming tidy datasets is good practice for future important functions that also require tidy datasets, such as lm(). After the official release of the tidyverse, Robinson wrote a follow-up blog advocating for the teaching of the entire tidyverse, not just ggplot2, to beginners. (Robinson, 2017) Robinson argues for teaching the coding aspect of introductory statistics using the tidyverse syntax based on his past teaching roles. Robinson claims to have been able to teach students with no prior coding knowledge on how to use the tidyverse’s facet_wrap() in 2-3 hours, which is considered a relatively advanced graphical tool. Robinson believes the role of coding within an introductory statistics course is as follows: to convince students that R is worth learning and to help them bolster their statistical knowledge. With this role in mind, Robinson writes that the tidyverse syntax encourages students to discover insights for provided datasets from the beginning, helping to both convince them of R’s importance and bolster their learning. In contrast, base R coding requires an additional understanding of its general syntax before learning tools to analyze datasets. Eventually, students need to learn base R techniques, but Robinson argues that base R can be taught in combination with the tools provided by the tidyverse, as to not bog down students by general coding rules. For example, functions such as lm() and mean() can be taught alongside the tidyverse’s summarize(). Robinson also argues against the teaching style that prioritizes learning conditionals and loops in these classes, since he believes that students require advanced techniques to make them effective. Robinson’s blog posts reference tidy dataframes. But what exactly constitutes a tidy dataframe? Dr. Hadley Wickham, long considered to be the tidyverse’s primary creator, explains below. (Wickham &amp; others, 2014) Many popular base R functions require tidy data inputs, as well as many tidyverse commands, which were created to work symmetrically with tidy datasets. A tidy dataset lists each variable as a separate column and every observation as its own row. The rows are ordered by the first variable, measured variables are listed after fixed ones, and related ones are located in adjacent columns to ease comparison. Wickham describes the benefits of tidy data outside of its requirement for many commands. The framework was inspired by his experience tackling real-world problems and then his subsequent role as a teacher. Wickham argues that most data transformation operations are easiest to perform when each variable is listed as its column. The consistent data structure allows users to start their analysis with the provided dataset instead of spending time working out the logistics of the data. Additionally, there are only a few commands needed to tidy messy data frames, called tidy tools, so once those commands are mastered, it should only take minutes to get directly into the analysis. In Wickham’s words, “Tidy tools are useful because the output of one tool can be used as the input to another.” Although the above arguments debate reasons for and against using different syntaxes, introductory statistics courses have been generalized by the release and subsequent update of The Guidelines for Assessment and Intruction in Statistics Education (GAISE). The GAISE also provides direction for the programming portion of the course with strict recommendations for how to teach statistical coding. (Carver et al., 2016) The GAISE was first endorsed by the American Statistical Association in 2005 and then updated in 2016 to reflect changes in datasets, technology, and professional demand for statistical literacy. The GAISE is recommended for introductory statistics education, but also applies to more advanced statistics courses, as it provides six general recommendations, which already were stated in the 2005 version: Teach statistical thinking Focus on conceptual understanding Integrate real data with a context and a purpose Foster active learning Use technology to explore concepts and analyze data Use assessments to improve and evaluate student learning The GAISE also states specific goals for students in introductory statistics courses: Students should become critical consumers of statistically-based results reported in popular media, recognizing whether reported results reasonably follow from the study and analysis conducted. Students should be able to recognize questions for which the investigative process in statistics would be useful and should be able to answer questions using the investigative process. Students should be able to produce graphical displays and numerical summaries and interpret what graphs do and do not reveal. Students should recognize and be able to explain the central role of variability in the field of statistics. Students should recognize and be able to explain the central role of randomness in designing studies and drawing conclusions. Students should gain experience with how statistical models, including multivariable models, are used. Students should demonstrate an understanding of, and ability to use, basic ideas of statistical inference, both hypothesis tests and interval estimation, in a variety of settings. Students should be able to interpret and draw conclusions from standard output from statistical software packages. Students should demonstrate an awareness of ethical issues associated with sound statistical practice. While the GAISE recommends the use of a programming tool as a supplement to the class, it does not state exactly which program students should use. In the next article, prominent professors at Duke University describe how and why they utilize R for statistics courses. (Çetinkaya-Rundel &amp; Rundel, 2018) Two instructors at Duke University, Dr. Mine Çetinkaya-Rundel and Dr. Colin Rundel, provide guidelines for how to use statistical programming tools in introductory statistics settings. As the statistical field continues to grow alongside programming tools, programming has morphed into a requirement, especially when handling with the practical and relevant datasets of today. Thus, the question has been shifted from a “should” to a “when” in discussing programming’s role in building a statistical education. The authors argue that students need to be exposed to programming, preferably R, early in their statistical education, but not on its own. They believe programming should be introduced in a supplemental fashion to give students the opportunity to grasp the topics covered in the traditional learning environment. R helps students bolster their understanding of lectures and also allows for an introduction to programming, as students who choose to progress through future statistics courses will not have to spend time learning basic coding concepts. In the instructors’ computation classes, they have a goal to computationally visualize something within the first 10 minutes of the first day to draw students to the importance of programming. In terms of software, the authors believe RStudio may help ease the students’ learning curve as an IDE relative to R and due to its auxiliary tools located outside of the main console. The tidyverse is not the only set of tools crafted to make R easier for beginners. A group of professors created a package designed for introductory programmers, as it equips students with a set of functions that will help them create complex situations with just a few lines of code. The package also provides a connection between base R and tidyverse plots, as it contains functions to switch between base R and ggplot2 visualization settings. (Pruim, Kaplan, &amp; Horton, 2017) Building off the tidyverse’s evolution, the mosaic package was created to help beginning coders develop advanced insights, as explained by the package’s authors. The authors believe that mosaic helps students to use programming in R as an asset from the start of their statistical learning. Mosaic depends on a group of packages within the tidyverse suite and contains commands such as mplot(), which allows students to create interactive plots in ggplot2. Mosaic is designed to be implemented alongside the tidyverse. Similar to how the tidyverse allows for students to start creating in R from the start, mosaic’s authors believe “One of the keys to successfully empowering students to think with data is providing them both a conceptual framework that allows them to know what to look for and how to interpret what they find, and a computational toolbox that allows them to do the looking.” By working through examples immediately, students will begin understand R’s error messages on so they can diagnose their own code issues and lower expectations for perfect code. As a package designed for beginning R users, mosaic is also equipped with specific functions such as rflip(), which helps explain binomial situations without the use of loops. The final two sources specifically pertain to the analysis conducted in this study. The first is a resource describing the benefits of team-based learning, which has been used in STA 101 courses to help students absorb the material outside of the traditional classroom setting. (Brame &amp; Director, 2016) “Team-based learning (TBL) is a structured form of small-group learning that emphasizes student preparation out of class and application of knowledge in class.” Proponents of TBL cite studies concluding that students learned more when placed in TBL settings compared to when they worked individually. TBL may be more beneficial for students because it forces the individual team members to debate amongst each other, thus bolstering or modifying their current knowledge to better comprehend the topic. Finally, as a check for potential biases, we analyzed the final project assignment documents for each STA 101 section examined in this study. Source: Final Project Assignment Documents for Each Class Overall, there were no significant changes in the STA 101 final project assignment document over the course of the 2013-2016 academic years. However, there were still small alterations that may have influenced the project submissions. For final projects completed in 2014 and onwards, student groups were placed in a situation at Paramount Pictures at a hypothetical job, whereas for Fall 2013 students, they were merely assigned the task at hand without the additional setting. Fall 2013 student groups were also not tasked with the audience score prediction component for a movie, but the covariate created in this study was not utilized in the analysis. Perhaps most importantly, though, the Fall 2013 final project assignment document features a small alteration in the grading section, where Dr. Çetinkaya-Rundel details the factors important in determining the final project grades. In the Fall 2013 semester, one section is titled “Creativity and Critical Thought”, compared to the document for more recent semesters, where the section is titled, “Critical Thought”. Although it is a minute wording discrepancy, the stating of the direct importance of creativity relative to student grades may have provided an extra incentive for Fall 2013 project groups when conducting their EDAs. "],
["3-data.html", "Chapter 3 Data 3.1 Final Project 3.2 Student Groups 3.3 Dataset Background", " Chapter 3 Data 3.1 Final Project The final project simulates a complete data analysis using relevant techniques covered throughout the STA 101 curriculum. The final project is the second of two that groups complete, but it differs drastically from the frst. Whereas the first project focuses on statistical inference and the dataset description, the second one is more comprehensive in its requirements, with specifications for exploratory data analysis (EDA) and regression sections, as well as for more innovative ways of looking at the data to address the final project’s directives. In the final project, student groups simulate a task in an R script or R Markdown document at a new music studio where their boss hypothetically assigns two goals: the boss wants to learn about the attributes that make a movie popular and also something new about movies. The final assignment contains five components—an introduction, a univariate analysis, a bivariate analysis, a multiple regression for predicting audience scores, and a conclusion. The regression section is relatively constant amongst groups in determining an optimal regression. However, in the univariate and bivariate analyses, student groups have the flexibility to explore a variety of facets of the data, which often separates projects from one another. The student project dataset has remained nearly the same for each class, and it tracks a random sample of American movies released since 1970. The student project dataset contains between 25 and 32 variables summmarizing the movie’s general characteristics such as runtime, genre, and production studio, award trackers such as best picture, best actor, best actress and best director indicator variables, as well as data from an online film review website (Rotten Tomatoes) and an online movie database (IMDB). Although variables such as the producing studio, the month and day of the week of both the theatre and DVD releases, IMDB rating (out of 10) and audience rating on Rotten Tomatoes were not included in the original 2013 dataset, student groups were provided with a sufficient amount of potential variables to analyze. The student project dataset’s most recent codebook is available in the Appendix as part of the Spring 2016 porject assignment. 3.2 Student Groups Students remained in the same groups they were assigned at the beginning of the semester as the groups were formed based on the results of both a pre-test and a survey. Both the pre-test and the survey were geared toward understanding each individual’s statistical background and literacy upon entering the course. Students worked through the lab assignments together, which consisted of exercises in R, and were encouraged to study together for exams as well. Student-based learning has been supported by studies showing that students absorb more when placed in smaller groups compared to when they worked individually. This may be due to increased collaboration, with debate amongst the team members that usually reinforces their understandings of the concepts covered in the course. Especially because of the large class sizes of STA 101, which total at least 70 students, professors utilize team-based learning techniques to help the students learn outside of a large lecture situation. 3.3 Dataset Background The dataset has been manually compiled from 205 STA 101 final group projects spanning the 2013-2016 academic years. 13 data entries were discarded since the complete project submissions could not be recovered. The projects’ contents are located on Duke’s Sakai sites of seven different classes, six of which were taught by Dr. Çetinkaya-Rundel. However, the professor does not affect much of the R learning over the course of the semester, since it occurs within the teaching assistant-run labs. Although there may be some slight instructor effects on coding abilities, the teaching assistants are the primary educators of R, and they change each semester. Therefore, some sections may have stronger grasps of coding for the final project, but it is likely to be minimal since teaching assistants are apprised of the upcoming week’s content via weekly meetings with the professor. Regardless, some discrepancies may be due to teaching assistants, and are noted in the Results section. The dataset constructed in this paper primarily focuses on actions taken by groups within the univariate and bivariate portions of the projects. In doing so, the the dataset contains variables summarizing relative creativity measures, as well as the projects’ depth and level of multivariate visualizations. Variable explanations will be available in the following chapter. "],
["4-methods.html", "Chapter 4 Methods 4.1 Creativity 4.2 Depth 4.3 Multivariate Visualization", " Chapter 4 Methods Since 98 percent of the projects were submitted either as an R script or R Markdown document, the student project code was analyzed directly on the downloaded submission documents for each group. Each project was examined and scored as either a 0, if the attribute was missing, or 1, if it was present, for 16 variables. The remaining three covariates identified the student projects by grade, index, and class. Due to privacy concerns, each student project was provided with an index, and the names of the students in each group were removed from their submission document. For the dataset utilized in this thesis, projects can solely be identified by their assigned index. A separate dataset serves as a link between the individual projects and their titles. The first few rows of the dataset compiled in this project are available below. head(project) # A tibble: 6 x 22 index grade sem r_rmd tidyverse create_new_var change_var sub_analysis &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 1 87.1 Fall… .r base R no no yes 2 2 89.2 Fall… .r base R yes no yes 3 3 80.2 Fall… .r base R no no yes 4 4 87.2 Fall… .r base R yes no yes 5 5 80.4 Fall… .r base R no no yes 6 7 90.2 Fall… .r base R no no no # … with 14 more variables: sub_data &lt;chr&gt;, viz_mult_make &lt;chr&gt;, # viz_mult_interpret &lt;chr&gt;, eda_theme &lt;chr&gt;, rel_data &lt;chr&gt;, # slr_fit &lt;chr&gt;, mlr_fit &lt;chr&gt;, mlr_check_cond &lt;chr&gt;, prediction &lt;chr&gt;, # ht &lt;chr&gt;, ht_check_cond &lt;chr&gt;, creative &lt;int&gt;, theme &lt;int&gt;, # multiviz &lt;int&gt; The student projects were not compiled into PDF or HTML files to confirm that the code worked, since it was a near-impossible task to determine which version of R packages the students utilized, as some of these commands are now defunct in the most recent versions of the packages. Because of this decision, this analysis operates under the assumption that the code produced the desired results in each project and did not require further debugging. The contents of the student project code were still analyzed for clarity, as well as creativeness, depth, and multivariate visualizations through the 16 indicator variables. These specific metrics were created since they are prominently emphasized throughout the GAISE. Code snippets will be provided in the following chapter to display examples that scored a one for distinct covariates. index: Project ID grade: Score on final project sem: Semester course taken r_rmd: Was the submission an R script (with prose of the project turned in as a Word document) or was the submission an R Markdown file? tidyverse: Project used &quot;tidyverse&quot; or &quot;base R&quot; syntax create_new_var: Students created a new variable based on existing variables, &quot;yes&quot; or &quot;no&quot; change_var: Students changed existing variables, &quot;yes&quot; or &quot;no&quot; sub_analysis: Students performed a subgroup analysis, &quot;yes&quot; or &quot;no&quot; sub_data: Students used data subsets for the entire project, &quot;yes&quot; or &quot;no&quot; viz_mult_make: Students employed visualizations with at least three variables, &quot;yes&quot; or &quot;no&quot; viz_mult_interpret: Students properly interpreted their 3+ variable visualization, &quot;yes&quot; or &quot;no&quot; eda_theme: Students used a consistent theme throughout their project, &quot;yes&quot; or &quot;no&quot; rel_data: Students supplemented their project theme with relevant data, &quot;yes&quot; or &quot;no&quot; slr_fit: Students fitted a simple linear regression, &quot;yes&quot; or &quot;no&quot; mlr_fit: Students fitted a multiple linear regression, &quot;yes&quot; or &quot;no&quot; mlr_check_cond: Students properly checked the conditions for their multiple linear regression, &quot;yes&quot; or &quot;no&quot; prediction: Students used their multiple linear regression to predict a movie’s audience score, &quot;yes&quot; or &quot;no&quot; ht: Students performed a hypothesis test, &quot;yes&quot; or &quot;no&quot; ht_check_cond: Students correctly checked the conditions for their hypothesis test, &quot;yes&quot; or &quot;no&quot; 4.1 Creativity The creativity metric seeks to encapsulate anything students coded that was not directly specified in the instructions but provided a purpose in their projects. The metric’s possible scores range from 0 to 4, as a project was scored with a single point for each of the following: Creation of new variable(s) based on existing variables Transformation of existing variables Existence of a subgroup analysis The use of a subset of the dataset for all steps of the project In the case of the student group projects utilizing the tidyverse syntax, groups were still given scores of 1s if they satisfied these conditions in base R form. While rare, two groups in labs taught in the tidyverse created or transformed covariates using Base R syntax, which was likely due to alternative resources, such as Stack Overflow, that prioritized base R solutions. Now, though, as the tidyverse’s popularity continues to grow, more online resources incorporate and promote tidyverse solutions. 4.1.1 Creation of New Variable(s) The creation of a new variable(s) is defined as any data manipulation throughout the EDA process where student groups compose a previously non-existing covariate. As an example, one group created a new variable tracking if a movie had won any of the following awards: best picture, best actor, best actress, or best director, and that project had this variable coded as “yes.” In order to score a 1, the student project also had to utilize the new variable within an aspect of their analysis. This condition filtered for groups that created unnecessary covariates. However, a score of 1 would be valid if the group did not use the variable in the inference or regression sections, but did explore the covariate in their EDA. 4.1.2 Transformation of Existing Variables Although related to the above covariate, the transformation of existing variables did not qualify as creating new variables, or vice versa. In this situation, a project would score a 1 if the student group mutated a variable already existing within the dataset, generally to highlight certain cases. For instance, a few project groups decided to change mpaa_rating to either “R” or “Other,” if the movie was not rated R. Similar to the requirements for scoring a 1 for the creation of new variable(s) covariate, the mutation was required to be employed to some end, as groups would have to provide at least a cursory analysis of the newly-mutated variable to score a 1. A distinction between scoring a 1 for this covariate and 1 for subsetting the dataset or conducting a subgroup analysis is that filtering the dataset for just entries that cover a portion of levels within a specific variable would qualify as a part of either a subgroup analysis or data subset, but not this covariate. Also, converting a factor variable that could be potentially read in as one when loading the dataset did not qualify as a mutation of an existing variable for this study. 4.1.3 Existence of Subgroup Analysis The presence of a subgroup analysis was measured in regards to creativity. Projects that received a one analyzed portions of the data during their EDA process. Groups could use an assortment of commands to satisfy a score of a 1, such as a normal boxplot, five-number summary of a specific variable within the movies dataset, or a subsetting with a corresponding numerical or graphical analysis. As an example, a project receiving a 1 for this category may have analyzed how the audience ratings for R rated movies compared to that of PG-13 movies in their bivariate analysis. 4.1.4 Use of a Data Subset for Project’s Entirety Although the use of a data subset covariate may seem similar to the one above, this variable received a 1 for a different aspect of the final group projects. Here, student groups are not just using the provided movies dataset for their EDA, inference, and regression—they are intentionally focusing on a few characteristics of the movie dataset. Student projects were not required to employ the same subsetted data throughout the entire analysis, but they did have to analyze related aspects of the movies dataset to qualify for a 1. For example, one student group scrutinized solely PG-13 rated movies for their final project, while another used the PG-13 rated movies subset for the EDA, PG-13 movies released after 2000 for the inference, and then the same PG-13 rated movies subset utilized in the EDA process for their regression analysis. 4.2 Depth The depth metric measures the level of depth of the analysis, both in terms of the statistical methods utilized and in terms of story-telling. Since the GAISE advises instructors to focus on students’ comprehension of important basic concepts rather than covering a multitude of topics with little focus, the depth metric qualifies the student groups’ understanding of the subjects covered in the project. The metric ranges from 0-2 and is scored with 1 point for each of the following: Presence of consistent theme throughout the project Use of relevant data The depth metric was created to qualify findings from the creativity score, to confirm that the syntax producing the more creative student projects also were at least of the same quality. Although creativity is imperative in these final projects, student groups also cannot skip parts of the data analysis cycle. 4.2.1 Consistent Theme In the world of data science, story-telling is such an important aspect, just as story-telling is designed to be for the STA 101 final group projects. A strong final project requires a story: a leading question, initial findings, subsequent analyses, and conclusion, all formed around a specific theme. Although this covariate’s scoring was subjective, the requirements for final projects to score a 1 were similar to those defining the creativity metric. To receive a 1, student groups clearly linked the steps in their analysis, often choosing to focus on a few aspects within the entire movie dataset. For instance, analyzing the impact of movie ratings on audience scores would qualify as a sufficient theme, but merely inspecting an assortment of different predictors with minimal reasoning would not register as 1. 4.2.2 Presence of Relevant Data Another subjective variable, the presence of relevant data was formed to complement the consistent theme covariate. To receive a 1 for this variable, student groups were required to sufficiently use R to create insights surrounding their chosen theme(s). The covariate addresses the issue that projects may have interesting themes but lack the analysis and coding quality to supplement their project. As an example, an aspect of a group project that would have scored a 1 for this category could have displayed the correlation coefficient between two numerical variables instead of plotting them together and failing to acknowledge the correlation in the project submission. If the majority of the coding could be employed to support the final project, the project group received a 1. 4.3 Multivariate Visualization The multivariate visualization metric accounts for both the presence and the insights derived from visualizations with at least three variables. Especially when using a movies dataset with many binary variables student groups often analyzed, visualizations with at least three variables and their subsequent interpretations can supplement important insights uncovered in the final projects. Also, the GAISE highlights the significance of teaching students how to interpret multivariate visualizaitons. “When students leave an introductory course, they will likely encounter situations within their own fields of study in which multiple variables relate to one another in intricate ways. We should prepare our students for challenging questions that require investigating and exploring relationships among more than two variables (Carver et al., 2016).” The metric ranges from 0-2 and is scored with 1 point for each of the following: Presence of a visualization with 3+ variables Interpretation of the multivariate visualization Although the two variables that constitute the multivariate visualization metric are related, as a project could not score a 1 for the interpretation if it did not contain a multivariate visualization, the presence of the visualization did not imply that there was a useful interpretation in the project write-up. 4.3.1 Presence of a Visualization with 3+ Variables The presence of a visualization with at least three variables is an objective variable simple to when dissecting final project submissions. Groups nearly always utilized colors to display a third variable along with two numerical ones on the x- and y-axes. To receive a score of a 1, projects were required to produce a graphical output with at least three aesthetics. For instance, some student groups created scatterplots between the critic and audience scores for all the movies in the given dataset with different colors for movies that won best picture at the Oscar’s that year. 4.3.2 Interpretation of Multivariate Visualization The interpretation of a multivariate visualization is not a completely objective variable. A project containing an incorrect or insufficient interpretation of its multivariate visualization would not receive a score of a 1. By insufficient, the project does not need to address every aspect of the visualization, but it needs to discuss a key insight to help bolster the overall final project. Otherwise, a useful explanation would deserve a score of a 1. "],
["5-results.html", "Chapter 5 Results 5.1 Creativity Metric 5.2 Depth Metric 5.3 Multivariate Visualization Metric", " Chapter 5 Results Both numerically and graphically, the student projects inspected in this study using the tidyverse syntax scored higher on all three of the developed metrics. Tidyverse projects were much more prevalent in the upper levels of the three variables, and their means and standard deviations significantly differed as well. 5.1 Creativity Metric Despite there being only 82 base R projects recorded to the 123 tidyverse projects, there more base R projects scored a 0 or 1 on the creativity metric than those using the tidyverse syntax. Overall, there was a single project that scored a perfect 4 out of the 193 projects, and the majority of the projects scored a 1 or 2 in the creativity metric. However, within the tidyverse projects, more than half (56.1 percent) registered at least a 2 on creativity, compared to just 20.7 percent of base R projects. The average creativity scores and corresponding standard deviations for projects utilizing the two syntaxes are available below as well: Syntax Mean SD Base R 1.1 0.6 Tidyverse 1.7 0.8 Syntax Mean Standard Deviation Base R 1.1 0.6 Tidyverse 1.7 0.8 FOR MINE: Which table should I use? One has SD as Standard Deviation When dissected by semester, the creativity score distributions did not notably vary for sections taught in base R. However, two sections—both employed the tidyverse syntax-from the Spring 2016 semester fared significantly better by their score breakdown than the other tidyverse courses. Without those two semesters of tidyverse projects, the rest of the tidyverse projects still boasted a higher score distribution than those of base R. Still, this discrepancy may be due to advanced instruction from the teaching assistants that encouraged groups to satisfy the requirements for higher creativty scores. Rhe following subsections will contain a comparison of base R and tidyverse student projects for each of the four variables combined to form the creativity metric, as well as potential reasons for the outcomes. 5.1.1 Creation of New Variable(s) Out of the four variables that form the creativity metric, the starkest difference between projects employing the two syntaxes was within the creation of new variable(s) covariate. Nearly half of all final projects using the tidyverse syntax featured a creation of a new variable, whereas less than a quarter of base R projects did. tidyverse create_new_var n proportion base R yes 18 24.0% tidyverse yes 59 50.0% This difference may be due to the ease in utilizing the tidyverse’s mutate() function, which allows users to create new variables using a single command. In base R, students are instructed to use $ notation, which may be harder to grasp due to issues with variable selection with $ and its usage in other base R tasks outside of creating new variables. 5.1.2 Transformation of Existing Variables While more than 75 project groups created new variables, far less opted to mutate existing ones in the movies dataset. Because the counts for both base R and tidyverse projects that satisfied this variable were lower, the resulting proportions were also much smaller. Regardless, there were more projects using the tidyverse syntax that mutated existing variables. tidyverse change_var n prop base R yes 2 2.7% tidyverse yes 9 7.6% The difference in proportions was not nearly as significant as it was for the creation of new variables and only differed marginally. This limited difference can be attributed to two factors. First, with the option to create their own variables, groups may not find transforming existing variables as appealing. Second, the mechanism to do so does not differ dramatically between the two syntaxes. For comparison, an example of changing an existing studio variable to “Warner Bros. Studios” or “Other” is listed in both Base R and the tidyverse: Base R: movies$studio &lt;- if_else(movies$studio == &quot;Warner Bros. Pictures&quot;, &quot;Warner Bros. Pictures&quot;, &quot;Other&quot;) Tidyverse: movies &lt;- movies %&gt;% mutate(studio = (if_else(studio == &quot;Warner Bros. Pictures&quot;, &quot;Warner Bros. Pictures&quot;, &quot;Other&quot;)) 5.1.3 Existence of Subgroup Analysis Out of all the covariates forming the creativity metric, the subgroup analysis was the most popular one satisfied for both base R and tidyverse projects. 93.5 percent of tidyverse projects performed a type of subgroup analysis, while more than 3/4 of base R projects did. tidyverse sub_analysis n prop base R yes 65 86.7% tidyverse yes 115 97.5% The popularity of this aspect within group projects may be explained by the copious ways student groups could perform a subgroup analysis. However, subgroup analyses may be easier to perform in the tidyverse due to the presence of the group_by() command, which is usually one of the most popular functions for beginning R users in the tidyverse. In contrast, base R’s by() function is not nearly as well-known. 5.1.4 Use of a Data Subset for Project’s Entirety The use of a subset of the provided movies dataset for the entire final project was also significantly more popular amongst tidyverse projects, as more than 15 percent of student projects using the tidyverse satisfied a score of a one for this covariate, compared to less than 5 percent of all base R projects. tidyverse sub_data n prop base R yes 4 5.3% tidyverse yes 20 16.9% Since there is little difference between the tidyverse’s filter() and base R’s subset() functions, this discrepancy might not have a distinct explanation. Perhaps, though, student groups using the tidyverse may have been more encouraged to utilize data subsets throughout their projects more often than those in base R because other creativity aspects were performed more frequently in tidyverse projects, so those groups may have gained additional insights that led them to use data subsets that base R project groups did not discover. 5.2 Depth Metric Although the depth metrics scores between final projects that employed base R syntax compared to those using the tidyverse do not have a similar discrepancy as the one for the creativity score, there is still a considerable difference in the depth metric distributions between projects of the two syntaxes. 48.8 percent of the projects using the tidyverse syntax scored a perfect 2 in the depth metric compared to 34.1 percent of base R projects, while the extreme majority of base R projects scored a 0 or 1 in the depth metric. Overall, most projects scored a one. The average depth scores and corresponding standard deviations for projects utilizing the two syntaxes are available below as well: Syntax Mean SD Base R 1.2 0.7 Tidyverse 1.4 0.7 FOR MINE: Which table should I use? One has SD as Standard Deviation Syntax Mean Standard Deviation Base R 1.2 0.7 Tidyverse 1.4 0.7 The results of the depth metric may be due to the simplicity of command chains in the tidyverse that make the project easier to code for beginners in R. Upon inspection by class section, the depth score distributions were largely similar, sans one of the Spring 2016 sections. Similar to how projects from this section performed on the creativity metric, they scored much higher on average in the depth category than projects from the other classes. The following subsections will contain a comparison of base R and tidyverse student projects for the two variables combined to form the depth metric. 5.2.1 Consistent Theme Within the theme metric, the variable tracking the presence of a consistent theme showcased a larger difference in proportions between base R and tidyverse student projects. Compared to base R projects, where 57.3 percent boasted a consistent theme, 71.5 percent of all tidyverse projects maintained uniformity theme-wise. tidyverse eda_theme n prop base R yes 47 62.7% tidyverse yes 88 74.6% The difference in proportions may potentially be attributed to the prevalence of select() and filter() within the tidyverse syntax, which allows users to choose specific columns within a data that satisfy a certain criteria, compared to base R, when student groups commonly utilized square brackets to delineate those same criteria. 5.2.2 Presence of Relevant Data Proportions for the presence of relevant data covariate were very similar, with just a 4.4 percent difference in proportions (64.2 for tidyverse compared to 59.8 for base R projects) between projects using the two syntaxes. tidyverse rel_data n prop base R yes 49 65.3% tidyverse yes 79 66.9% The presence of relevant supporting data should not be greatly impacted by the particular coding syntax student groups employed, which may explain the small difference in proportions for this variable. 5.3 Multivariate Visualization Metric Between projects using the two different syntaxes, the most significant difference in any of the three metrics occurred within the multivariate visualization metric, where just one final project in base R even displayed a plot containing at least three different variables. The majority of all projects did not include multivariate visualizations, but projects using the tidyverse syntax were more popular within higher scores of the metric in general, with 13 percent scoring a perfect 2. No projects in base R reached the same score. The average multivariate visualization scores and corresponding standard deviations for projects utilizing the two syntaxes are available below as well. Although the statistics do not represent the difference in the metric between projects of the two syntaxes, there is still a distinct divide. Syntax Mean SD Base R 0.0 0.1 Tidyverse 0.4 0.7 FOR MINE: Which table should I use? One has SD as Standard Deviation Syntax Mean Standard Deviation Base R 0.0 0.1 Tidyverse 0.4 0.7 Although we have observed a higher rate and score distribution of tidyverse projects, the trend is not consistent by semester. One of the Fall 2015 sections included 10 projects with a multivariate visualization score of at least a one, while the other did not contain a single project showcasing a multivariate plot. Similar to the reasoning stated in the Creativity section, this may be due to the emphasis and quality of instruction from the teaching assistants (which differ by class section) in regards to creating plots with at least three variables. The following subsections will contain a comparison of base R and tidyverse student projects for the two variables combined to form the multivariate visualization metric. 5.3.1 Presence of a Visualization with 3+ Variables Only one project coded in solely base R displayed a visualization with at least three variables, compared to 30 tidyverse projects. Percentage-wise, too, the tidyverse projects were more likely to contain a multivariate visualization. tidyverse viz_mult_make n prop base R yes 1 1.3% tidyverse yes 30 25.4% These results may be due to the differences in base R’s plot() function relative to the tidyverse’s ggplot(). Whereas plot() requires extra commands to add graphical aesthetics besides x- and y-variables, the aes() command embedded within ggplot() provides an easy platform for tidyverse users to employ other aesthetics besides just the x- and y-variables. For example, code is listed below that would satisfy a score of one when using the two syntaxes. Base R: movies.color &lt;- rep(&quot;pink&quot;, length(movies$best_pic_nom)) movies.color[movies$best_pic_nom == &quot;yes&quot;] &lt;- &quot;blue&quot; plot(audience_score ~ critics_score, col = movies.color, data = movies) legend(col = c(&quot;pink&quot;, &quot;blue&quot;)) Tidyverse: ggplot(data = movies, aes(x = critics_score, y = audience_score, color = best_pic_nom)) + geom_point() FOR MINE: This code is correct, right? 5.3.2 Interpretation of Multivariate Visualization No student project using solely base R interpreted a multivariate plot, whereas 13 percent of projects utilizing the tidyverse did. Although the proportion satisfying a score of a 1 is not very high, more than half of tidyverse projects that formed a visualization with at least three variables (16 out of 30) contained sufficient intepretations of the outputs. tidyverse viz_mult_interpret n prop tidyverse yes 16 13.6% Theoretically, the difference in proportions between projects primarily using base R compared to the tidyverse should not drastically differ. However, since there were more tidyverse projects that contained multivariate plots, there was bound to be a difference in this covariate. In general, though, the plots should not deviate for interpretation, though some users may find comfort in viewing graphs provided by their most commonly-used syntax. "],
["6-educational-resources.html", "Chapter 6 Educational Resources 6.1 Infer Vignettes 6.2 Lab Enhancements", " Chapter 6 Educational Resources After analyzing the retrospective study, we provided two resources intended for use in statistical instruction to reflect our insights in favor of the tidyverse syntax. We altered current STA 101 labs to further adhere to the GAISE manual and provided two code samples with explanations for infer, an R package created to perform inference tasks using a tidy framework. 6.1 Infer Vignettes Currently, the tidyverse contains packages to clean, mutate, model and visualize data, but not to perform inference tasks. Due to the popularity and demand for the tidyverse framework, a group of professors created a relatively new package titled infer, which is fashioned as the tidyverse solution to inference. Like packages such as dplyr and ggplot2, infer relies on a few commands to execute a variety of tasks and benefits from the piping structure used throughout the tidyverse. Unfortunately, infer does not presently include detailed examples of the package’s usage. Therefore, we decided to write two vignettes—longer code samples embedded within data analysis stories—to provide infer users with vivid examples and explanations for proper usage of the package. By inference, the two primary endeavors are performing hypothesis tests and creating confidence intervals—hence a vignette for each. The vignettes also utilize separate aspects of the same dataset, to provide users the comfort of a consistent data source while exposing them to tasks using both numerical and categorical variables. The complete vignettes are available in the Appendix. 6.2 Lab Enhancements Based on the results gleaned from analyzing the student project data from introductory statistics courses at Duke University, we decided to fully apply tidyverse syntax and methods to introductory statistics labs. OpenIntro Statistics is an open-source textbook approved for use at the undergraduate level by the American Institute of Mathematics, and the labs accompanying OpenIntro textbooks are available online and are used by students at many institutions, including at Duke University. These labs were updated in 2016 to incorporate tidyverse syntax for data visualization and wrangling, though statistical inference still relied on Base R syntax. As part of this project, we have updated the code introduced in the labs to fully leverage the Tidyverse ecosystem, including the infer package. Since the most recent update of the labs to incorporate tidyverse syntax, recommendations around introducing data visualization with ggplot2 have changed. Previous practice used the qplot() (quick plot) function, which has a simpler API than the ggplot() function, but is more cumbersome to produce complex multivariate visualizations with. With this update, we have completely abandoned the use of qplot() and replaced it with ggplot(), resulting in changes in associated code. Two main reasons for this change are the existence of plethora of resources for debugging ggplot() as well as ease of expansion to complex visualizations. Another major update was in the labs that focus on statistical inference. Previous versions of the labs used a custom function called inference() from the oilabs package, the R package used to supplement OpenIntro. This function, designed with the best intentions in mind for highlighting the unified nature of statistical inference across various hypothesis tests and confidence intervals introduced in introductory statistics curricula, over time morphed into a function that is too extensive for efficient debugging and too customized for use beyond the introductory statistics classroom. The infer package, released in 2018, was heavily inspired by the inference() function, but significantly improved the API for tidy statistical inference and tied it closely to how both we and the GAISE recommend introducing statistical inference in introductory statistics curricula. The goal of this package “is to perform inference using an expressive statistical grammar that coheres with the tidy design framework,” as per its R documentation. For instance, here is code for generating a two-sided hypothesis test using the two methods, with the inference() function first. inference(y = y_variable, x = x_variable, data = data, statistic = &quot;mean&quot;, type = &quot;ht&quot;, null = 0, alternative = &quot;twosided&quot;, method = “theoretical&quot;) obs_diff &lt;- data %&gt;% specify(dependent ~ independent) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;yes&quot;, &quot;no&quot;)) null &lt;- data %&gt;% specify(dependent ~ independent) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;yes&quot;, &quot;no&quot;)) null %&gt;% get_p_value(obs_stat = obs_diff, direction = &quot;two_sided&quot;) And here is an example of code creating a 95 percent confidence interval using inference() and infer, respectively. inference(y = response, data = data, statistic = &quot;proportion&quot;, type = &quot;ci&quot;, method = &quot;theoretical&quot;, success = &quot;yes&quot;) data %&gt;% specify(formula = text_ind ~ NULL, success = &quot;yes&quot;) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;prop&quot;) %&gt;% get_ci(level = .95) The labs focusing on statistical inference have thus been updated with the current infer syntax in order to provide students with a workflow they can extend outside of their classroom setting alongside the tidyverse, as well as one with available online resources. A few of the labs also featured datasets that have either been out of use for the past few years and will continue to be considered outmoded, were convoluted and required supplementary information, or intentionally or unintentionally promoted gender stereotypes. These datasets, and the corresponding labs, were updated with more robust and interesting material, as summarized in the table below. The datasets were analyzed prior to insertion to affirm that they would have the bandwidth to seamlessly fit the particular focus of the labs. Previous Dataset Reason for Change New Dataset Body Dimensions Focuses on weight comparison across binary genders Fast Food Nutritional Facts Atheism and Religion Unverified Dataset Youth Risk Behavior Surveillance System Baseball Required further dataset explanation Human Freedom Index North Carolina Births Dated + Not relevant for most undergrads Youth Risk Behavior Surveillance System "],
["conclusion.html", "Conclusion 6.3 Future Work", " Conclusion FUTURE WORK hadley comments: -he imagines that if you first learn with tidy verse, students aren’t becoming real R programmers, might want to look at that look for “function(){“ -if we took code for base R and tidy verse and gave them to students who have never seen code, might be able to read tidy verse code easier to read first *in the future, might be able to look at this Due to the discrepancies in creativity, depth, and multivariate visualization scores between students projects using base R and others employing the tidyverse syntax, we recommend that the tidyverse syntax should be the primary syntax when using R as a supplement for introductory statistics courses. Although the sample is limited by solely analyzing Duke’s STA 101 final projects, the standardization of STA 101 classes provides an optimal baseline for comparison. Another potential source of bias, the project assignment document, can be nullified by the lack of wording differences since the Fall 2013 document (a base R class) supplemented by a similar creativity metric distribution for the Fall 2013 class as other base R section. As such, since there was shown to be higher scores in the three metrics for projects using the tidyverse syntax, the project language is not considered to be a confounding variable. For our scoring mechanism, initially, we inputted the grades received for the assignment prior to coding the indicator variables. However, after the first two classes were coded, we recognized that the grades might provide a potential source of error, so the grades were subsequently inputted for all future projects after the entire submission was scored. In an attempt to fully expell any bias, we confirmed the variable coding a second time while ignoring the grades received, and tough scoring situations were confirmed via collaboration between Mr. Feder and Dr. Çetinkaya-Rundel. Since we could not find a significant confounding factor, we can attribute the distinctions in creativity, depth, and multivariate visualization scores to the R syntax. Additionally, since the final projects were randomly scored by course, and then later checked, we are confident that there was no bias in the coding of the indicator variables We strongly encourage instructors to teach introductory R using the tidyverse syntax, as well as infer for inference tasks, as we believe that the tidyverse’s consistency encourages students to produce more creative and higher quality work while tightly adhering to the GAISE. We decided to create educational materials instead of attempting a form of modeling due to our desire to contribute to the current introductory statistics curriculum. 6.3 Future Work We encourage others to build upon this analysis in an experimental form, since this study is solely retrospective. Although we have attempted to eliminate all potential sources of bias, a causal analysis can be much more unambiguous in a randomized trial. Perhaps similar to the study performed by (Myint et al., 2019), a randomized experiment conducted through an online educational company, instead focusing on distinct code differences, could be very effective. In the future, it may be interesting to show tidyverse and base R code snippets accomplishing the same tasks to students with no programming background to determine whether one syntax is easier to initially read and understand. Also, as the infer package grows in popularity, the effectiveness of the infer package in completing inference tasks should be confirmed. If you feel it necessary to include an appendix, it goes here. --> "],
["A-spring-semester-sta-101-final-project-assignment-document.html", "A 2016 Spring Semester STA 101 Final Project Assignment Document A.1 Data A.2 Stages of the project A.3 Submission A.4 Teamwork and grading A.5 Honor code A.6 Tips", " A 2016 Spring Semester STA 101 Final Project Assignment Document Listed below is the final project assignment document, which includes a codebook for the movies dataset, given to students who enrolled in the course in the Spring 2016 iteration: You and your teammates work for Paramount Pictures. Your boss has just acquired data about how much audiences and critics like movies as well as numerous other variables about the movies. She is interested in learning what attributes make a movie popular. She is also interested in learning something new about movies. She wants your team to figure it all out. As part of this project you will complete exploratory data analysis (EDA), inference, modeling, and prediction. You have been introduced to some of these concepts already, and you will learn about the others later in the course. The data can be loaded directly in RStudio using the following command: load(url(&quot;https://stat.duke.edu/~mc301/data/movies.Rdata&quot;)) A.1 Data The data set is comprised of 651 randomly sampled movies produced and released before 2016. Some of these variables are only there for informational purposes and do not make any sense to include in a statistical analysis. It is up to you to decide which variables are meaningful and which should be omitted. For example information in the the actor1 through actor5 variables was used to determine whether the movie casts an actor or actress who won a best actor or actress Oscar. You might also choose to omit certain observations or restructure some of the variables to make them suitable for answering your research questions. When you are fitting a model you should also be careful about collinearity, as some of these variables may be dependent on each other. A.1.1 Codebook title: Title of movie title_type: Type of movie (Documentary, Feature Film, TV Movie) genre: Genre of movie (Action &amp; Adventure, Comedy, Documentary, Drama, 1. Horror, Mystery &amp; Suspense, Other) runtime: Runtime of movie (in minutes) mpaa_rating: MPAA rating of the movie (G, PG, PG-13, R, Unrated) studio: Studio that produced the movie thtr_rel_year: Year the movie is released in theaters thtr_rel_month: Month the movie is released in theaters thtr_rel_day: Day of the month the movie is released in theaters dvd_rel_year: Year the movie is released on DVD dvd_rel_month: Month the movie is released on DVD dvd_rel_day: Day of the month the movie is released on DVD imdb_rating: Rating on IMDB imdb_num_votes: Number of votes on IMDB critics_rating: Categorical variable for critics rating on Rotten Tomatoes 1. (Certified Fresh, Fresh, Rotten) critics_score: Critics score on Rotten Tomatoes audience_rating: Categorical variable for audience rating on Rotten Tomatoes 1. (Spilled, Upright) audience_score: Audience score on Rotten Tomatoes (response variable) best_pic_nom: Whether or not the movie was nominated for a best picture 1. Oscar (no, yes) best_pic_win: Whether or not the movie won a best picture Oscar (no, yes) best_actor_win: Whether or not one of the main actors in the movie ever won an Oscar (no, yes) – note that this is not necessarily whether the actor won an Oscar for their role in the given movie best_actress win: Whether or not one of the main actresses in the movie ever won an Oscar (no, yes) – not that this is not necessarily whether the actresses won an Oscar for their role in the given movie best_dir_win: Whether or not the director of the movie ever won an Oscar (no, yes) – not that this is not necessarily whether the director won an Oscar for the given movie top200_box: Whether or not the movie is in the Top 200 Box Office list on BoxOfficeMojo (no, yes) director: Director of the movie actor1: First main actor/actress in the abridged cast of the movie actor2: Second main actor/actress in the abridged cast of the movie actor3: Third main actor/actress in the abridged cast of the movie actor4: Fourth main actor/actress in the abridged cast of the movie actor5: Fifth main actor/actress in the abridged cast of the movie imdb_url: Link to IMDB page for the movie rt_url: Link to Rotten Tomatoes page for the movie A.2 Stages of the project You will complete this project in two stages: Stage 1: Proposal (25 points) Stage 2: Poster and presentation (75 points) The remainder of this document outlines the requirements and expectations for both stages of the project. You should read the entire document before getting started. The requirements and expectations for Stage 1 will only make sense in context of those for Stage 2. A.2.1 Stage 1: Proposal (25 points) A.2.1.1 Content Your proposal should contain the following: Data: (2 points) Describe how the observations in the sample are collected, and the implications of this data collection method on the scope of inference (generalizability / causality). Research questions: (6 points) Come up with at least three research questions that you want to answer using these data. You should phrase your research questions in a way that matches up with the scope of inference your dataset allows for. Make sure that at least two of these questions involve at least three variables. You are welcomed to create new variables based on existing ones. Note that you will have the option to update / revise / change these questions for your poster at the end of the semester. EDA: (9 points) Perform exploratory data analysis that adresses each of the three research questions you outlined above. Your EDA should contain numerical summaries and visualizations. Each R output and plot should be accompanied by a brief interpretation. Timeline: (4 points) Sketch out a timeline for the work you will do to complete this project. Be as detailed and precise as possible. And be realistic – discuss course schedules, travel plans, etc. Teamwork: (4 points) Describe in detail how you will divvy up the work between team members and what aspects of the project you will complete together as a team. Note that during the poster session each member needs to be able to answer questions about all aspects of the work, regardless of whether they took the lead on that section or not. A.2.1.2 Format &amp; length Your proposal should be written using the R Markdown template, so that all R code, output, and plots will be automatically included in your write up. Download the template for the proposal: download.file(&quot;http://stat.duke.edu/courses/Spring16/sta101.001/rmd/sta101_proposal.Rmd&quot;, destfile = &quot;sta101_proposal.Rmd&quot;) Your proposal should not exceed 5 pages (view a print preview to determined length). A.2.1.3 Grading Your proposal will be graded out of 25 points (as outlined above), and will make up 25% of your overall project score. The following will result in deductions: Late: -1 points for each day late Reproducibility issues, requiring to make changes to the R Markdown file to knit the document: -3 points Each page over limit: -2 points per page (view print preview to confirm length) A.2.2 Stage 2: Poster and presentation (75 points) A.2.2.1 Content Introduction: Outline your main research question(s). EDA: Do some exploratory data analysis to tell an “interesting” story about movies. Instead of limiting yourself to relationships between just two variables, broaden the scope of your analysis and employ creative approaches that evaluate relationships between two variables while controlling for another. Inference: Use one of your research questions (or come up with a new one depending on feedback from the proposal) that can be answered with a hypothesis test or a confidence interval, e.g. “Is there a difference in mean audience scores between genres?” or “What is the average difference in audience scores between movies that do and do not feature without oscar winner actors?” This question could be used to shed some light on your choice of the “best” linear model. Carry out the appropriate inference task to answer your question. Modeling: Develop a multiple linear regression model to predict a numerical variable in the dataset. Prediction: Pick a movie from 2015 (a new movie that is not in the sample) and do a prediction for this movie using your the model you developed (and the predict function in R). Also quantify the uncertainty around this prediction using an appropriate interval. Conclusion: A brief summary of your findings from the previous sections without repeating your statements from earlier as well as a discussion of what you have learned about the data and your research question(s). You should also discuss any shortcomings of your current study (either due to data collection or methodology) and include ideas for possible future research. A.2.2.2 Poster format &amp; length Poster: We suggest using a tri-fold poster. You can organize it however you like. You do not need to get your poster professionally printed. You can see sample posters from previous years at your professor’s office. R Markdown: All code used to generate the statistics and plots on your poster should be organized and submitted in an R Markdown document. Download the template for the project: download.file(&quot;http://stat.duke.edu/courses/Spring16/sta101.001/rmd/sta101_project.Rmd&quot;, destfile = &quot;sta101_project.Rmd&quot;) There is no length limit for this document. A.2.2.3 Presentation format &amp; length You will give a four minute presentation of your work. Each team member must speak during this presentation. The time limit is firm, you will be asked to stop at the end of four minutes. This is not a lot of time, therefore you must decide carefully what you will highlight during your presentation and practice to make sure you can fit everything you want to say in the time limit. A.2.2.4 Grading Your poster (and accompanying code) and presentation will be graded out of 75 points, and will make up 75% of your overall project score. Grading of the project will take into account: Correctness: Are the procedures and explanations correct? Presentation: What was the quality of the presentation and poster? Content/Critical thought: Did your think carefully about the problem? Tidyness: Is your code organized well? Your team scores will be based on the following components: 25 points - poster 20 points - presentation 20 points - code 10 points - classmates’ evaluation A.3 Submission Online on Sakai under Assignments. These will be time stamped, and late penalty will be applied based on the time stamp. Only one submission per team required. R Markdown file (.Rmd) HTML output (.html) We will download your R Markdown file and run your code to confirm reproducibility of your work. Grading will be based on the document we compile, so make sure that your R Markdown file contains everything necessary to compile your entire work. A.4 Teamwork and grading Team scores for both the proposal and the poster will be adjusted based on team peer evaluation data to determine each student’s indivudual grade. You will be asked to fill out a survey where you rate the contribution of each team member. Filling out the survey is a prerequisite for receiving a project score. All team members must be present at the poster session. Failure to do so will result in a 0 on the project for the absent team member. Note that each student must complete the project and score at least 30% of total possible points on the project in order to pass this class. A.5 Honor code You may not discuss this project in any way with anyone outside your team, besides the professor and TAs. Failure to abide by this policy will result in a 0 for all teams involved. A.6 Tips This project is an opportunity to apply what you have learned about descriptive statistics, graphical methods, correlation and regression, and hypothesis testing and confidence intervals. The goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather to show that you are proficient at using R at a basic level and that you are proficient at interpreting and presenting the results. You might consider critiquing your own method, such as issues pertaining to the reliability of the data and the appropriateness of the statistical analysis you used within the context of this specific data set. "],
["B-updated-openintro-labs.html", "B Updated OpenIntro Labs", " B Updated OpenIntro Labs Here is a link to the Github repository containing the updated STA 101 labs: INSERT LINK "],
["C-infer-vignettes-1.html", "C Infer Vignettes", " C Infer Vignettes Here is a link to the two vignettes that will be released with the next update to infer: INSERT LINK "],
["references.html", "References", " References "]
]
